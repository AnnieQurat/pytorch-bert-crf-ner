{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import print_function\n",
    "import itertools\n",
    "import loader\n",
    "import torch\n",
    "import time\n",
    "from datetime import datetime\n",
    "import _pickle as cPickle\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import visdom\n",
    "from utils import *\n",
    "from loader import *\n",
    "from model import BiLSTM_CRF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'all_emb': 1,\n",
      "    'best_idx': 0,\n",
      "    'cap_dim': 0,\n",
      "    'char_bidirect': 1,\n",
      "    'char_dim': 25,\n",
      "    'char_lstm_dim': 25,\n",
      "    'char_mode': 'CNN',\n",
      "    'crf': 1,\n",
      "    'dev': 'data/eng.testa',\n",
      "    'dropout': 0.5,\n",
      "    'epochs': 10001,\n",
      "    'eval_path': 'evaluation',\n",
      "    'eval_script': 'evaluation\\\\conlleval',\n",
      "    'eval_temp': 'evaluation\\\\temp',\n",
      "    'loss': 'loss.txt',\n",
      "    'lower': 1,\n",
      "    'mapping_file': 'models/mapping.pkl',\n",
      "    'model_name': 'models\\\\lstm_crf.model',\n",
      "    'models_path': 'models',\n",
      "    'name': 'lstm_crf.model',\n",
      "    'pre_emb': 'data/glove.6B.100d.txt',\n",
      "    'reload': 0,\n",
      "    'score': 'data/temp/score.txt',\n",
      "    'tag_scheme': 'iobes',\n",
      "    'test': 'data/eng.testb',\n",
      "    'test_train': 'data/eng.train54019',\n",
      "    'train': 'data/eng.train',\n",
      "    'use_gpu': 0,\n",
      "    'word_bidirect': 1,\n",
      "    'word_dim': 100,\n",
      "    'word_lstm_dim': 200,\n",
      "    'zeros': 0}\n"
     ]
    }
   ],
   "source": [
    "class Myconfig():\n",
    "    def __init__(self):\n",
    "        self.epochs       = 10001\n",
    "        self.train        = 'data/eng.train'  # Train set location\n",
    "        self.dev          = 'data/eng.testa'  # Dev set location\n",
    "        self.test         = 'data/eng.testb'  # Test set location\"\n",
    "        self.test_train   = 'data/eng.train54019'  # test train\n",
    "        self.score        = 'data/temp/score.txt'  # score file location\n",
    "        self.tag_scheme   = 'iobes'  # Tagging scheme (IOB or IOBES), IOB -> IOBES(B O -> S O / B B -> S B|S / I O -> E O)\n",
    "        self.lower        = 1  # \"Lowercase words (this will not affect character inputs)\n",
    "        self.zeros        = 0  # Replace digits with 0\n",
    "        self.char_dim     = 25  # Char embedding dimension\n",
    "        self.char_lstm_dim= 25  # Char LSTM hidden layer size\n",
    "        self.char_bidirect= 1  # Use a bidirectional LSTM for chars\n",
    "        self.word_dim     = 100  # Token embedding dimension\n",
    "        self.word_lstm_dim= 200  # Token LSTM hidden layer size\n",
    "        self.word_bidirect= 1  # Use a bidirectional LSTM for words\n",
    "        self.pre_emb      = 'data/glove.6B.100d.txt'  # Location of pretrained embeddings\n",
    "        self.all_emb      = 1  # Load all embeddings\n",
    "        self.cap_dim      = 0  # Capitalization feature dimension (0 to disable)\n",
    "        self.crf          = 1  # Use CRF (0 to disable)\n",
    "        self.dropout      = 0.5  # Droupout on the input (0 = no dropout)\n",
    "        self.reload       = 0  # Reload the last saved model\n",
    "        self.use_gpu      = 0  # whether or not to ues gpu\n",
    "        self.loss         = 'loss.txt'  # loss file location\n",
    "        self.name         = 'lstm_crf.model'  # model name\n",
    "        self.char_mode    = 'CNN'  # ['CNN', 'LSTM']  # char_CNN or char_LSTM\n",
    "        self.mapping_file = 'models/mapping.pkl'  # dump parameter - word_to_id, tag_to_id, char_to_id, parameters, word_embeds\n",
    "        self.models_path  = \"models\"\n",
    "        self.model_name   = os.path.join(self.models_path, self.name)\n",
    "        self.eval_path    = \"evaluation\"\n",
    "        self.eval_temp    = os.path.join(self.eval_path, \"temp\")\n",
    "        self.eval_script  = os.path.join(self.eval_path, \"conlleval\")\n",
    "        self.best_idx     = 0  # to get the index of the best test f1 score\n",
    "\n",
    "opts = Myconfig()\n",
    "def _print_config(config):\n",
    "    import pprint\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(vars(config))\n",
    "_print_config(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(opts.train)\n",
    "assert os.path.isfile(opts.dev)\n",
    "assert os.path.isfile(opts.test)\n",
    "assert opts.char_dim > 0 or opts.word_dim > 0\n",
    "assert 0. <= opts.dropout < 1.0\n",
    "assert opts.tag_scheme in ['iob', 'iobes']\n",
    "assert not opts.all_emb or opts.pre_emb\n",
    "assert not opts.pre_emb or opts.word_dim > 0\n",
    "assert not opts.pre_emb or os.path.isfile(opts.pre_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(opts.eval_script):\n",
    "    raise Exception('CoNLL evaluation script not found at \"%s\"' % eval_script)\n",
    "if not os.path.exists(opts.eval_temp):\n",
    "    os.makedirs(opts.eval_temp)\n",
    "if not os.path.exists(opts.models_path):\n",
    "    os.makedirs(opts.models_path)\n",
    "\n",
    "lower = opts.lower\n",
    "zeros = opts.zeros\n",
    "tag_scheme = opts.tag_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = loader.load_sentences(opts.train, lower, zeros)\n",
    "dev_sentences = loader.load_sentences(opts.dev, lower, zeros)\n",
    "test_sentences = loader.load_sentences(opts.test, lower, zeros)\n",
    "test_train_sentences = loader.load_sentences(opts.test_train, lower, zeros)\n",
    "\n",
    "update_tag_scheme(train_sentences, tag_scheme)\n",
    "update_tag_scheme(dev_sentences, tag_scheme)\n",
    "update_tag_scheme(test_sentences, tag_scheme)\n",
    "update_tag_scheme(test_train_sentences, tag_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7518 unique words (203621 in total)\n",
      "Loading pretrained embeddings from data/glove.6B.100d.txt...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dico_words_train = word_mapping(train_sentences, lower)[0]\n",
    "\n",
    "dico_words, word_to_id, id_to_word = augment_with_pretrained(\n",
    "        dico_words_train.copy(),\n",
    "        opts.pre_emb,\n",
    "        list(itertools.chain.from_iterable(\n",
    "            [[w[0] for w in s] for s in dev_sentences + test_sentences])\n",
    "        ) if not opts.all_emb else None\n",
    "    )\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85 unique characters\n",
      "Found 19 unique named entity tags\n",
      "14041 / 3250 / 3453 sentences in train / dev / test.\n"
     ]
    }
   ],
   "source": [
    "dico_chars, char_to_id, id_to_char = char_mapping(train_sentences)\n",
    "dico_tags, tag_to_id, id_to_tag = tag_mapping(train_sentences)\n",
    "\n",
    "train_data     = prepare_dataset(train_sentences,      word_to_id, char_to_id, tag_to_id, lower)\n",
    "dev_data       = prepare_dataset(dev_sentences,        word_to_id, char_to_id, tag_to_id, lower)\n",
    "test_data      = prepare_dataset(test_sentences,       word_to_id, char_to_id, tag_to_id, lower)\n",
    "test_train_data= prepare_dataset(test_train_sentences, word_to_id, char_to_id, tag_to_id, lower)\n",
    "print(\"%i / %i / %i sentences in train / dev / test.\" % (\n",
    "    len(train_data), len(dev_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 pretrained embeddings.\n"
     ]
    }
   ],
   "source": [
    "all_word_embeds = {}\n",
    "for i, line in enumerate(codecs.open(opts.pre_emb, 'r', 'utf-8')):\n",
    "    s = line.strip().split()\n",
    "    if len(s) == opts.word_dim + 1:\n",
    "        all_word_embeds[s[0]] = np.array([float(i) for i in s[1:]])\n",
    "\n",
    "word_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (len(word_to_id), opts.word_dim))\n",
    "\n",
    "for w in word_to_id:\n",
    "    if w in all_word_embeds:\n",
    "        word_embeds[word_to_id[w]] = all_word_embeds[w]\n",
    "    elif w.lower() in all_word_embeds:\n",
    "        word_embeds[word_to_id[w]] = all_word_embeds[w.lower()]\n",
    "\n",
    "print('Loaded %i pretrained embeddings.' % len(all_word_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_to_id:  400176\n",
      "tag_to_id : 19 ea, {'O': 0, 'S-LOC': 1, 'B-PER': 2, 'E-PER': 3, 'S-ORG': 4, 'S-MISC': 5, 'B-ORG': 6, 'E-ORG': 7, 'S-PER': 8, 'I-ORG': 9, 'B-LOC': 10, 'E-LOC': 11, 'B-MISC': 12, 'E-MISC': 13, 'I-MISC': 14, 'I-PER': 15, 'I-LOC': 16, '<START>': 17, '<STOP>': 18}\n"
     ]
    }
   ],
   "source": [
    "with open(opts.mapping_file, 'wb') as f:\n",
    "    mappings = {\n",
    "        'word_to_id': word_to_id,\n",
    "        'tag_to_id': tag_to_id,\n",
    "        'char_to_id': char_to_id,\n",
    "        'parameters': opts,\n",
    "        'word_embeds': word_embeds\n",
    "    }\n",
    "    cPickle.dump(mappings, f)\n",
    "print('word_to_id: ', len(word_to_id))\n",
    "print('tag_to_id : %d ea, %s' % (len(tag_to_id), tag_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_mode: CNN, out_channels: 25, hidden_dim: 200, \n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM_CRF(vocab_size     =len(word_to_id),\n",
    "                   tag_to_ix      =tag_to_id,\n",
    "                   embedding_dim  =opts.word_dim,\n",
    "                   hidden_dim     =opts.word_lstm_dim,\n",
    "                   use_gpu        =opts.use_gpu,\n",
    "                   char_to_ix     =char_to_id,\n",
    "                   pre_word_embeds=word_embeds,\n",
    "                   use_crf        =opts.crf,\n",
    "                   char_mode      =opts.char_mode)\n",
    "                   # n_cap=4,\n",
    "                   # cap_embedding_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opts.reload:\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "if opts.use_gpu:\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "learning_rate  = 0.015\n",
    "optimizer      = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "losses         = []\n",
    "loss           = 0.0\n",
    "best_dev_F     = -1.0\n",
    "best_test_F    = -1.0\n",
    "best_train_F   = -1.0\n",
    "all_F          = [[0, 0, 0]]  # train, valid, test data F1 score\n",
    "plot_every     = 500\n",
    "eval_every     = 20\n",
    "count          = 0\n",
    "vis            = visdom.Visdom()  # use visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(model, datas, best_F, epoch, display_confusion_matrix = False):\n",
    "    prediction = []\n",
    "    save = False\n",
    "    new_F = 0.0\n",
    "    confusion_matrix = torch.zeros((len(tag_to_id) - 2, len(tag_to_id) - 2))  # number of tag - 2(start, stop)\n",
    "    for data in datas:\n",
    "        ground_truth_id = data['tags']\n",
    "        words    = data['str_words'] # ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
    "        chars2   = data['chars']     # [[36, 58], [7, 1, 62, 1, 12, 3, 8], ...\n",
    "        caps     = data['caps']      # [1, 0, 2, 0, 0, 0, 2, 0, 0]\n",
    "\n",
    "        ## char embedding\n",
    "        if opts.char_mode == 'LSTM':\n",
    "            chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
    "            matching_char = {}\n",
    "            for i, ci in enumerate(chars2):\n",
    "                for j, cj in enumerate(chars2_sorted):\n",
    "                    if ci == cj and not j in matching_char and not i in matching_char.values():\n",
    "                        matching_char[j] = i\n",
    "                        continue\n",
    "            chars2_length = [len(c) for c in chars2_sorted]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2_sorted):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "\n",
    "        if opts.char_mode == 'CNN':\n",
    "            matching_char = {}\n",
    "            chars2_length = [len(c) for c in chars2]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "        \n",
    "        eval_sentence_in = Variable(torch.LongTensor(data['words']))\n",
    "        eval_caps  = Variable(torch.LongTensor(caps))\n",
    "        # Send variables to gpu\n",
    "        if opts.use_gpu:\n",
    "            eval_sentence_in= eval_sentence_in.to(device)\n",
    "            chars2_mask     = chars2_mask.to(device)\n",
    "            eval_caps       = eval_caps.to(device)\n",
    "        \n",
    "        ## inference\n",
    "        ## input : sentence, caption, words, word length, word matching dict\n",
    "        ## output: score : tensor(237.0103, device='cpu', grad_fn=<SelectBackward>)\n",
    "        ##         target_sequence : [4, 0, 5, 0, 0, 0, 5, 0, 0]\n",
    "        \n",
    "        score, predict_target_sequence = model(sentence= eval_sentence_in,\n",
    "                                               caps    = eval_caps,                             \n",
    "                                               chars        = chars2_mask,\n",
    "                                               chars2_length= chars2_length,\n",
    "                                               matching_char= matching_char)  # target이 없다.\n",
    "        predicted_id = predict_target_sequence    \n",
    "        # word, true_id, pred_id\n",
    "        # EU       4     4\n",
    "        # rejects  0     0\n",
    "        # German   5     5\n",
    "        # call     0     0\n",
    "        # to       0     0\n",
    "        # boycott  0     0\n",
    "        # British  5     5\n",
    "        # lamb     0     0\n",
    "        # .        0     0\n",
    "        for (word, true_id, pred_id) in zip(words, ground_truth_id, predicted_id):\n",
    "            line = ' '.join([word, id_to_tag[true_id], id_to_tag[pred_id]])\n",
    "            prediction.append(line)\n",
    "            confusion_matrix[true_id, pred_id] += 1 # 17 x 17 \n",
    "        prediction.append('')\n",
    "    predf  = opts.eval_temp + '/pred.' + opts.name\n",
    "    scoref = opts.eval_temp + '/score.' + opts.name \n",
    "    \n",
    "    ## inference Print - /evaluation/temp/pred.test\n",
    "    ## word   true   prediction\n",
    "    ## prediction\n",
    "    # EU S-ORG O\n",
    "    # rejects O O\n",
    "    # German S-MISC O\n",
    "    # call O O\n",
    "    with open(predf, 'w') as f:\n",
    "        f.write('\\n'.join(prediction))\n",
    "    # evaluation run the conlleval file in the folder\n",
    "    # system - 'evaluation/conlleval < evaluation/temp/pred.test > evaluation/temp/score.test'\n",
    "    os.system('%s < %s > %s' % (opts.eval_script, predf, scoref))\n",
    "    \n",
    "    ## display\n",
    "    \n",
    "    # Evaluation proceeds with above command 'scoref' score is stored in the path\n",
    "    # best f1 score, save=True, return, and save it\n",
    "    eval_lines = [l.rstrip() for l in codecs.open(scoref, 'r', 'utf8')]\n",
    "    for i, line in enumerate(eval_lines):\n",
    "        print(line)\n",
    "        if i == 1:\n",
    "            new_F = float(line.strip().split()[-1])\n",
    "            if new_F > best_F:\n",
    "                best_F = new_F\n",
    "                best_idx = epoch\n",
    "                save = True\n",
    "                print('the best F is ', new_F)\n",
    "    \n",
    "    ## display, confusion matrix\n",
    "    \n",
    "    if display_confusion_matrix:\n",
    "        print((\"{: >2}{: >7}{: >7}%s{: >9}\" % (\"{: >6}\" * confusion_matrix.size(0))).format(\n",
    "                \"ID\", \"NE\", \"Total\",\n",
    "                *([id_to_tag[i] for i in range(confusion_matrix.size(0))] + [\"Percent\"])\n",
    "                ))\n",
    "        for i in range(confusion_matrix.size(0)):\n",
    "            print((\"{: >2}{: >7}{: >7}%s{: >9}\" % (\"{: >6}\" * confusion_matrix.size(0))).format(\n",
    "                    str(i), id_to_tag[i], str(int(confusion_matrix[i].sum())),\n",
    "                    *([int(confusion_matrix[i][j]) for j in range(confusion_matrix.size(0))] +\n",
    "                      [\"%.2f\" % (confusion_matrix[i][i] * 100. / max(1, confusion_matrix[i].sum()))])\n",
    "                    ))\n",
    "    # best_F: The best ever F score\n",
    "    # new_F : Now sample  F score\n",
    "        # save  : Best F score, if new, save = True return\n",
    "    return best_F, new_F, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start -2021-01-05 10:29:07.897798\n"
     ]
    }
   ],
   "source": [
    "opts.epochs = 1\n",
    "data_num    = 20\n",
    "\n",
    "start_time = datetime.now();print('training start -%s' % start_time);\n",
    "every_losses, epoch_losses = [], []\n",
    "\n",
    "## Train\n",
    "model.train(True)  # False validation, test - dropout, batchnorm control\n",
    "for epoch in range(0, opts.epochs):\n",
    "    in_epoch_losses = []\n",
    "    epoch_time = datetime.now();\n",
    "    # train_data random index\n",
    "#     for i, index in enumerate(np.random.permutation(len(train_data[:data_num]))):\n",
    "    for i, index in enumerate(np.random.permutation(len(train_data))):\n",
    "        count += 1  # batch = 1\n",
    "        \n",
    "        # data\n",
    "        #{'str_words': ['Willem', 'II', 'Tilburg', '1', 'RKC', 'Waalwijk', '3'],\n",
    "        # 'words': [2987, 2089, 2970, 17, 2925, 3369, 23],\n",
    "        # 'chars': [[57, 5, 9, 9, 1, 14],\n",
    "        #          [35, 35],\n",
    "        #          [31, 5, 9, 21, 13, 7, 17],\n",
    "        #          [23],\n",
    "        #          [38, 60, 34],\n",
    "        #          [57, 2, 2, 9, 20, 5, 62, 29],\n",
    "        #          [39]],\n",
    "        # 'caps': [2, 1, 2, 0, 1, 2, 0],\n",
    "        # 'tags': [6, 9, 7, 0, 6, 7, 0]}        \n",
    "        data = train_data[index]\n",
    "        model.zero_grad()\n",
    "\n",
    "        sentence_in = Variable(torch.LongTensor(data['words']))  # 'words': [2987, 2089, 2970, 17, 2925, 3369, 23]\n",
    "        targets = torch.LongTensor(data['tags'])                 # tags'  : [6, 9, 7, 0, 6, 7, 0]}\n",
    "        caps = Variable(torch.LongTensor(data['caps']))          # 'caps' : [2, 1, 2, 0, 1, 2, 0]\n",
    "        chars2 = data['chars']  # Letters of each word are grouped together  # 'chars': [[57, 5, 9, 9, 1, 14], [35, 35], [31, 5, 9, 21, 13, 7, 17], ...]\n",
    "        ############################################################################\n",
    "        ## char embeddings\n",
    "        # input  : chars2  - list, ex : [[54, 1], [8, 2, 5, 10], [2]]\n",
    "        # output : matching_char(chars2_sorted char2 , ex, sorting if the first is the actual third line -> {1:3, ....}), cnn empty if used dictionary\n",
    "        #          chars2_length(list's word length, [2, 4, 1]), \n",
    "        #          chars2_mask(Find the number of words, the length of the longest word)\n",
    "        ############################################################################\n",
    "        ######### 1. char lstm\n",
    "        if opts.char_mode == 'LSTM':\n",
    "            # Sort by character length\n",
    "            chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
    "            matching_char = {}\n",
    "\n",
    "            # 0 [54, 1]\n",
    "            # 1 [8, 2, 5, 10]\n",
    "\n",
    "            # !! sorting a list, sorting Matching with the actual list\n",
    "            # ex, sorting If the first is the actual third line-> {1:3, ....}\n",
    "            for i, ci in enumerate(chars2):\n",
    "                for j, cj in enumerate(chars2_sorted):\n",
    "                    if ci == cj and not j in matching_char and not i in matching_char.values():\n",
    "                        matching_char[j] = i\n",
    "                        continue          \n",
    "            # chars2_length, [2, 4, 1, 8, 4, ...]\n",
    "            chars2_length = [len(c) for c in chars2_sorted]\n",
    "            # char_maxl, Find the longest font size\n",
    "            char_maxl = max(chars2_length)\n",
    "            # chars2_mask : (Number of words, maximum word length)\n",
    "            chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2_sorted):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "        ############################################################################\n",
    "        ######### 2. char cnn\n",
    "        if opts.char_mode == 'CNN':\n",
    "            matching_char = {}  # If you use cnn, it is an empty dict\n",
    "            chars2_length = [len(c) for c in chars2]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "        ############################################################################\n",
    "        # Send variables to gpu\n",
    "        if opts.use_gpu:\n",
    "            sentence_in = sentence_in.to(device)\n",
    "            targets     = targets.to(device)\n",
    "            chars2_mask = chars2_mask.to(device)\n",
    "            caps        = caps.to(device)\n",
    "        ############################################################################\n",
    "        ## sentence,\n",
    "        neg_log_likelihood = model.neg_log_likelihood(sentence = sentence_in, \n",
    "                                                      tags = targets, \n",
    "                                                      chars2 = chars2_mask, \n",
    "                                                      caps = caps, \n",
    "                                                      chars2_length = chars2_length, \n",
    "                                                      matching_char = matching_char)\n",
    "        # Loss divided by the number of words per sentence, loss/2 for sentences with two words\n",
    "        loss = float(neg_log_likelihood.cpu().detach().numpy()) / len(data['words'])\n",
    "        in_epoch_losses.append(loss)\n",
    "#         loss += float(neg_log_likelihood.cpu().detach().numpy()) / len(data['words'])\n",
    "#         in_epoch_losses.append(loss)\n",
    "                \n",
    "        neg_log_likelihood.backward()  # backprop\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)  # gradient clipping, so to not have exploding gradient\n",
    "        optimizer.step()  # optimization\n",
    "        ############################################################################\n",
    "        ############################################################################\n",
    "\n",
    "\n",
    "    epoch_losses.append(np.mean(in_epoch_losses))  # Calculate the average loss of epoch\n",
    "    ############################################################################\n",
    "    ## epoch number, Evaluation\n",
    "    ############################################################################\n",
    "    model.train(False)  # For evaluation, training X\n",
    "    best_train_F, new_train_F, _,    _       = evaluating(model, test_train_data, best_train_F, epoch)\n",
    "    best_test_F,  new_test_F,  _,    opts.best_idx= evaluating(model, test_data,       best_test_F, epoch)\n",
    "    # If the result of validation is best, save is set to True, so that the model is saved.\n",
    "    best_dev_F,   new_dev_F,   save, _       = evaluating(model, dev_data,        best_dev_F, epoch)\n",
    "    \n",
    "    if save: torch.save(model, opts.model_name)\n",
    "\n",
    "    all_F.append([new_train_F, new_dev_F, new_test_F])\n",
    "    ############################################################################\n",
    "    ## visdom output\n",
    "    ############################################################################\n",
    "    ## 1. epoch F score graph output\n",
    "    Fwin = 'F-score of {train, dev, test}_' + opts.name\n",
    "    vis.line(X   = np.array([epoch]),\n",
    "             Y   = np.array([all_F[epoch]]),\n",
    "             win =Fwin, \n",
    "             opts={'title': Fwin, 'legend': ['train', 'dev', 'test']}, update='append')\n",
    "    ## 2. epoch loss graph output\n",
    "    losswin = 'loss_' + opts.name\n",
    "    vis.line(X = np.array([epoch]),\n",
    "             Y = np.array([epoch_losses[epoch]]),\n",
    "             win=losswin, opts={'title': losswin, 'legend': ['loss']}, update='append')\n",
    "    ## 3. epoch loss text output\n",
    "    textwin = 'loss_text_' + opts.name\n",
    "    text = '</p>'.join([str(n) +' - '+ str(round(l, 3)) for n, l in enumerate(epoch_losses)])\n",
    "    vis.text(text, \n",
    "             win=textwin, opts={'title': textwin})\n",
    "    ############################################################################\n",
    "    \n",
    "    model.train(True)  # Since the evaluation is over, turn it on again\n",
    "    # \n",
    "    adjust_learning_rate(optimizer, lr=learning_rate/(1+0.05*count/len(train_data)))\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    print('%d-start/current/epoch/require:%s / %s / %s / %s' % (epoch, start_time, datetime.now(), (datetime.now()-epoch_time), (datetime.now() - start_time)))\n",
    "    print('F train/valid/test : %.2f / %.2f / %.2f - %d'%(best_train_F, best_dev_F, best_test_F, opts.best_idx))\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epoch_losses)\n",
    "    plt.plot(opts.best_idx, epoch_losses[opts.best_idx], 'ro')\n",
    "    plt.title('loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(all_F)\n",
    "    plt.plot([opts.best_idx, opts.best_idx, opts.best_idx], all_F[opts.best_idx], 'ro')\n",
    "    plt.title('F score')\n",
    "    plt.legend(['train', 'dev', 'test'])\n",
    "    plt.ylim([90.5, 100])\n",
    "    plt.show()\n",
    "    \n",
    "    best_test_F, new_test_F,  _, _ = evaluating(model, test_data, best_test_F, epoch, display_confusion_matrix=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opts.mapping_file, 'wb') as f:\n",
    "    mappings = {\n",
    "        'word_to_id'  : word_to_id,\n",
    "        'tag_to_id'   : tag_to_id,\n",
    "        'char_to_id'  : char_to_id,\n",
    "        'parameters'  : opts,\n",
    "        'word_embeds' : word_embeds,\n",
    "        'epoch_losses': epoch_losses,\n",
    "        'all_F'       : all_F\n",
    "    }\n",
    "    cPickle.dump(mappings, f)\n",
    "print('word_to_id: ', len(word_to_id))\n",
    "print('tag_to_id : %d, %s' % (len(tag_to_id), tag_to_id))\n",
    "\n",
    "max_temp=max_idx=0\n",
    "for i in range(len(all_F)):\n",
    "    if all_F[i][2] > max_temp:\n",
    "        max_temp = all_F[i][2]\n",
    "        max_idx = i\n",
    "print(max_idx, max_temp)\n",
    "plt.plot(all_F)\n",
    "plt.plot([max_idx, max_idx, max_idx], all_F[max_idx], 'ro')\n",
    "plt.title('F score - test')\n",
    "plt.legend(['train', 'dev', 'test'])\n",
    "plt.ylim([90.5,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
